---
title: "TEfits basics"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{TEfits basics}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup,echo=F}
library(TEfits)
```


## Introduction to Time-Evolving Fits

Data is described, interpreted, and tested using indices such as d prime, mean, or psychometric function threshold. This package serves to allow the same questions to be asked about time-evolving aspects of these indices.

Nonlinear regression is on the fringes of many analysis domains. In the immortal words that accompany the codification of the so-called "Power Law of Practice," Newell and Rosenbloom (1981) asserted that "Curve fitting without benefit of a model is notoriously a black art." This notoriety has hardly diminished in the intervening decades, although the use of some methods (e.g., Generalized Additive Models, Gaussian Processes) has certainly become more popular. 

The `TEfits` package is intended to assist in the implementation and interpretation of nonlinear regression with a heavy emphasis on interpretability of parameters. Rather than a "black art," parameters fit by `TEfits` are meant to reflect human-interpretable representations of time-evolving processes. Error functions, nonlinear ("change") functions linking parameters and time to predicted values, parameter and prediction boundaries, and goodness-of-fit indices are intended to be clear and adjustable. An equal emphasis is on ease of use: minimal arguments are necessary to begin using the primary function, `TEfit()`, and many common tasks are fully automated (e.g., optimization starting points, bootstrapping).

The underlying goal of this package is to simplify the analysis of data [a response variable] that manifests as a saturating function of time. Many heuristics included in the package rely on this notion, e.g., exponential and power functions
only are allowed to decay [saturate]. Additionally, the default assumption is that the saturation should largely take place within the observed time. That is, if parameters of a time-evolving function are to be reliably estimated, the inflection point of the associated curve must be observed. This constraint allows the rejection of extreme curve shape parameters (i.e., "rate" parameters) which greatly improves the identifiability of nonlinear functions. That is to say, constraining this parameter reduces the possibility of mimicry of parameter combinations and the associated multiple error minima.

Other excellent packages exist that facilitate nonlinear regression (e.g., *brms*, *gnm*, *lme4*, *nlme*) as well as *stats::nls*. *TEfits* is designed to fill a gap in these previous packages in two ways: 
  
  1. Allow for non-normal distributions of response variables. Note that this means more than generalizing a (non-) linear model using a link function; in real data the likelihood function defining the error profile itself varies depending on the data being modeled. *brms* is the only one of the packages above that also allows this flexibility.

2. Lower the amount of expertise needed to implement nonlinear models. A core goal of *TEfits* is to minimize the barriers to parametric time-dependent analysis. While more custom and complex models can certainly be specified in a full modeling language (e.g., *Stan*) or one of its front-end packages (e.g., *brms*), *TEfits* is designed to open the door to users with minimal experience with nonlinear regression specification and implementation.

## Drawing inferences

How should model fit be assessed? How to tell whether using a time-evolving function to describe your data is "worth it?" Three primary methods are recommended: (1) Compare BIC -- a negative delta BIC indicates that your parameters decreased error enough to justify their inclusion; (2) Compare conditional independence -- a Spearman correlation between your response variable and time that is smaller with the model than without the model indicates that your model is removing a pre-existing bias in your data, and proportional Spearman change can help with this comparison; (3) See how robust the directional trend is -- bootstrap the model and see whether the time-dependent increase (or decrease) in predicted values is consistent across your resampled parameters. Each of these methods of evaluating fit are available from the summary() function. Of course, the above
can also be used to compare fits with different change functions, covariates, fixed parameters, etc.

## For complete control

For more traditional nonlinear regression, in which a formula is explicitly stated, define the formula in the control list. Convergence criterion can also be set arbitrarily low to simply return the best-fit model after the desired number of runs (note that, regardless of the number of runs, a warning regarding nonconvergence will likely be printed).

`TEfit(varIn[,c('y','time_v')],control=tef_control(explicit='y~a_par+log(1/time_v^b_par)',nTries=1E3,convergeTol=1E-10))`

## References

Cochrane, A., Cui, L., Hubbard, E. M., & Green, C. S. (2019). "Approximate number system" training: A perceptual learning approach. Attention, Perception, & Psychophysics, 81(3), 621-636. https://doi.org/10.3758/s13414-018-01636-w

Cochrane, A., Simmering, V. R., Austerweil, J. L., & Green, C. S. (2018). Rapid Learning in Early Attentional Processing: Bayesian Estimation of Trial-by-Trial Updating. Proceedings of the Annual Meeting of the Cognitive Science Society, 40, 232-237.

Gold, J. I., Law, C.-T., Connolly, P., & Bennur, S. (2010). Relationships Between the Threshold and Slope of Psychometric and Neurometric Functions During Perceptual Learning: Implications for Neuronal Pooling. Journal of Neurophysiology, 103(1), 140-154. https://doi.org/10.1152/jn.00744.2009

Kattner, F., Cochrane, A., Cox, C. R., Gorman, T. E., & Green, C. S. (2017). Perceptual Learning Generalization from Sequential Perceptual Training as a Change in Learning Rate. Current Biology, 27(6), 840-846. https://doi.org/10.1016/j.cub.2017.01.046

Kattner, F., Cochrane, A., & Green, C. S. (2017). Trial-dependent psychometric functions accounting for perceptual learning in 2-AFC discrimination tasks. Journal of Vision, 17(11), 3. https://doi.org/10.1167/17.11.3

Klein, S. A. (2001). Measuring, estimating, and understanding the psychometric function: A commentary. Perception & Psychophysics, 63(8), 1421-1455. https://doi.org/10.3758/BF03194552

Newell, A., & Rosenbloom, P. S. (1981). Mechanisms of skill acquisition and the law of practice. In J. R. Anderson (Ed.), Cognitive skills and their acquisition (pp. 1-51). Lawrence Erlbaum.

Strasburger, H. (2001). Converting between measures of slope of the psychometric function. Perception & Psychophysics, 63(8), 1348-1355. https://doi.org/10.3758/BF03194547

Wichmann, F. A., & Hill, N. J. (2001). The psychometric function: I. Fitting, sampling, and goodness of fit. Perception & Psychophysics, 63(8), 1293-1313. https://doi.org/10.3758/BF03194544

